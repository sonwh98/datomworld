#:blog{:title "Benchmark: The Price of Introspection (Datoms vs Bytecode)",
       :date #inst "2026-01-20T00:00:00.000-00:00",
       :abstract [:p "We benchmarked two VM implementations: a traditional recursive array-based bytecode interpreter versus the new linear Datom Stream architecture. The result? Optimized Bytecode is " [:strong "60x faster"] " than Datom Streams. Here is why we choose the slower architecture anyway."]
       :content
       [:section.blog-article
        [:div.section-inner
         [:article
          :$blog-title
          :$blog-date
          [:h2 "The Experiment"]
          [:p "We pitted two implementations of the Yin VM against each other running a deeply nested arithmetic expression (2^12 nested additions generated via code)."]
          [:ul.bulleted
           [:li [:strong "Recursive Array Bytecode (Traditional):"] " Uses a tight loop with O(1) vector access to execute bytecode."]
           [:li [:strong "Linear Datom Stream (New):"] " Flattens the AST into a linear stream of execution datoms stored in a DataScript/Datalevin database."]]

          [:h2 "The Results"]

          [:p "After fixing a performance bug (LazySeq O(N) access) in the array implementation, the true baseline emerged. We also implemented an \"Optimized Stream\" that pre-fetches AST data to avoid DB queries in the hot loop."]

          [:pre [:code

                 "Recursive Array Bytecode:     20.39 ms

          Linear Datom Stream:        1151.38 ms

          Optimized Datom Stream:      443.08 ms"]]

          [:p "The Standard Datom Stream is ~56x slower. The Optimized Stream (which keeps data as Datoms but hydrates them into memory before execution) is ~22x slower."]

          [:h2 "Why is Datom Stream Slower?"]

          [:p "Three architectural costs are paid for every instruction:"]

          [:h3 "1. Database Overhead"]
          [:p "Instead of an O(1) array index lookup `(nth bytes pc)`, the Datom VM performs a `d/pull` query against the in-memory database to retrieve the instruction and its operands. While fast, a DB query involves hashing, map lookups, and object allocation that dwarfs a simple array access."]

          [:h3 "2. Transaction Overhead"]
          [:p "JIT-compiling closures involves `d/transact!`. Even in-memory, ensuring transactional consistency (ACID) adds latency that a raw memory write does not have."]

          [:h3 "3. Object Allocation"]
          [:p "The Datom VM works with rich immutable maps for every step, whereas the Bytecode VM works mostly with primitive integers and lightweight vectors."]

          [:h2 "Why We Choose the Slower Architecture"]
          [:p "If it's 60x slower, why use it? Because " [:strong "speed is not the only metric"] "."]
          [:p "The Datom Stream architecture buys us capabilities that are impossible with raw bytecode:"]
          [:ul.bulleted
           [:li [:strong "Queryability:"] " We can run Datalog queries " [:em "during execution"] " to inspect the state of the VM. \"Find all functions that accessed variable X\" becomes a query, not a debugger breakpoint."]
           [:li [:strong "Provenance:"] " Every execution step is linked to its source AST node. We never lose the \"why\" behind an operation."]
           [:li [:strong "Time-Travel:"] " Because execution is a stream of facts, we can rewind, replay, and fork execution state trivially."]
           [:li [:strong "Security:"] " The DB acts as a capability-secure sandbox naturally."]]

          [:h2 "The Realization"]
          [:p "This benchmark clarifies the trade-off of Datom.World: " [:strong "We trade raw compute speed for semantic richness."]]
          [:p "For number-crunching (matrix multiplication, physics simulations), use optimized bytecode or native code. For " [:strong "orchestration, business logic, and intelligent agents"] ", where understanding " [:em "what"] " the code is doing is more important than how fast it loops, the Datom Stream is the superior architecture."]
          [:p "It turns the runtime into a database. And for our use cases, a queryable runtime is worth the cost."]

          [:p [:strong "Learn more:"]]
          [:ul.bulleted
           [:li [:a {:href "/blog/ast-datom-streams-bytecode-performance.blog"} "AST Datom Streams: Bytecode Performance with Semantic Preservation"] " (the theory)"]
           [:li [:a {:href "/blog/ast-higher-dimensional-datom-streams.blog"} "AST as Higher Dimensional Construction of Datom Streams"] " (why ASTs are materialized views)"]
           [:li [:a {:href "/blog/continuations-universal-semantic-kernel.blog"} "Why Continuations Are the Universal Semantic Kernel"] " (why we use loop/recur and continuations)"]]]]]}