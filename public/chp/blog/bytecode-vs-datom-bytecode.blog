#:blog{:title "Benchmark: The Price of Introspection (Datoms vs Bytecode)",
       :date #inst "2026-01-20T00:00:00.000-00:00",
       :abstract [:p "We benchmarked two VM implementations: a traditional bytecode interpreter versus the Datom Stream architecture. The result? Bytecode is " [:strong "6x to 44x faster"] " depending on platform and optimization. Here is why we choose the slower architecture anyway."]
       :content
       [:section.blog-article
        [:div.section-inner
         [:article
          :$blog-title
          :$blog-date
          [:h2 "The Experiment"]
          [:p "We pitted two implementations of the Yin VM against each other running a deeply nested arithmetic expression (2^12 nested additions generated via code)."]
          [:ul.bulleted
           [:li [:strong "Recursive Array Bytecode (Traditional):"] " Uses a tight loop with O(1) vector access to execute bytecode."]
           [:li [:strong "Linear Datom Stream (New):"] " Flattens the AST into a linear stream of execution datoms stored in a DataScript/Datalevin database."]]

          [:h2 "The Results"]

          [:p "After fixing a performance bug (LazySeq O(N) access) in the array implementation, the true baseline emerged. We also implemented an \"Optimized Stream\" that pre-fetches AST data to avoid DB queries in the hot loop. Both platforms use DataScript for consistency."]

          [:h3 "JVM (Clojure + DataScript)"]
          [:pre [:code
                 "Recursive Array Bytecode:     20 ms
Linear Datom Stream:         891 ms
Optimized Datom Stream:      122 ms"]]

          [:h3 "Node.js (ClojureScript + DataScript)"]
          [:pre [:code
                 "Recursive Array Bytecode:     33 ms
Linear Datom Stream:         550 ms
Optimized Datom Stream:      460 ms"]]

          [:p "On the JVM, the Standard Datom Stream is ~44x slower than bytecode. The Optimized Stream (which pre-fetches datoms into memory) cuts this to ~6x slower, a " [:strong "7x improvement"] "."]

          [:p "On Node.js, the optimization provides only ~1.2x speedup. The Standard Datom Stream is ~16x slower than bytecode; Optimized is ~14x slower."]

          [:h3 "Why Does the Optimization Help More on JVM?"]

          [:p "V8's JIT aggressively optimizes the DataScript query path, making " [:code "d/pull"] " nearly as fast as pre-fetched data. The JVM's HotSpot takes longer to warm up and benefits more from eliminating repeated queries."]

          [:p "Interestingly, Node.js runs the baseline Datom Stream faster than JVM (550ms vs 891ms), but JVM catches up with the optimized version (122ms vs 460ms)."]

          [:h2 "Why is Datom Stream Slower?"]

          [:p "Three architectural costs are paid for every instruction:"]

          [:h3 "1. Database Overhead"]
          [:p "Instead of an O(1) array index lookup `(nth bytes pc)`, the Datom VM performs a `d/pull` query against the in-memory database to retrieve the instruction and its operands. While fast, a DB query involves hashing, map lookups, and object allocation that dwarfs a simple array access."]

          [:h3 "2. Transaction Overhead"]
          [:p "JIT-compiling closures involves `d/transact!`. Even in-memory, ensuring transactional consistency (ACID) adds latency that a raw memory write does not have."]

          [:h3 "3. Object Allocation"]
          [:p "The Datom VM works with rich immutable maps for every step, whereas the Bytecode VM works mostly with primitive integers and lightweight vectors."]

          [:h2 "Why We Choose the Slower Architecture"]
          [:p "If it's 6x to 44x slower, why use it? Because " [:strong "speed is not the only metric"] "."]
          [:p "The Datom Stream architecture buys us capabilities that are impossible with raw bytecode:"]
          [:ul.bulleted
           [:li [:strong "Queryability:"] " We can run Datalog queries " [:em "during execution"] " to inspect the state of the VM. \"Find all functions that accessed variable X\" becomes a query, not a debugger breakpoint."]
           [:li [:strong "Provenance:"] " Every execution step is linked to its source AST node. We never lose the \"why\" behind an operation."]
           [:li [:strong "Time-Travel:"] " Because execution is a stream of facts, we can rewind, replay, and fork execution state trivially."]
           [:li [:strong "Security:"] " The DB acts as a capability-secure sandbox naturally."]]

          [:h2 "The Realization"]
          [:p "This benchmark clarifies the trade-off of Datom.World: " [:strong "We trade raw compute speed for semantic richness."]]
          [:p "For number-crunching (matrix multiplication, physics simulations), use optimized bytecode or native code. For " [:strong "orchestration, business logic, and intelligent agents"] ", where understanding " [:em "what"] " the code is doing is more important than how fast it loops, the Datom Stream is the superior architecture."]
          [:p "It turns the runtime into a database. And for our use cases, a queryable runtime is worth the cost."]

          [:p [:strong "Learn more:"]]
          [:ul.bulleted
           [:li [:a {:href "/blog/ast-datom-streams-bytecode-performance.blog"} "AST Datom Streams: Bytecode Performance with Semantic Preservation"] " (the theory)"]
           [:li [:a {:href "/blog/ast-higher-dimensional-datom-streams.blog"} "AST as Higher Dimensional Construction of Datom Streams"] " (why ASTs are materialized views)"]
           [:li [:a {:href "/blog/continuations-universal-semantic-kernel.blog"} "Why Continuations Are the Universal Semantic Kernel"] " (why we use loop/recur and continuations)"]]]]]}